{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json \n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "from byol_pytorch import BYOL\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/data/dlcv/hw4/office/train\"\n",
    "valid_path = \"/data/dlcv/hw4/office/val\"\n",
    "train_csv = \"/data/dlcv/hw4/office/train.csv\"\n",
    "valid_csv = \"/data/dlcv/hw4/office/val.csv\"\n",
    "label2id_path = \"./label2id.json\"\n",
    "ckpt_path = \"./ckpt/finetune\"\n",
    "pretrained_path = \"/data/jhccc/dlcv/hw4-jhc659/ckpt/uma/resnetLast.pth\"\n",
    "retrain_path = \"/data/jhccc/dlcv/hw4-jhc659/ckpt/finetune/settingE_best.pth\"\n",
    "os.makedirs(ckpt_path, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(3)\n",
    "print('Device used:', device)\n",
    "\n",
    "img_size = 128\n",
    "train_bz = 128\n",
    "valid_bz = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, inputPath, csvPath, label2idPath, transform=None):\n",
    "        self.inputPath = inputPath\n",
    "        self.transform = transform\n",
    "        with open(label2idPath, 'r') as j:\n",
    "            self.label2id = json.loads(j.read())\n",
    "        self.inputName = []\n",
    "        df = pd.read_csv(csvPath)\n",
    "        for i in range(len(df)):\n",
    "            self.inputName.append((df.loc[i].filename, self.label2id[df.loc[i].label]))\n",
    "        print(self.inputName[0])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.inputPath, self.inputName[index][0]))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        id = self.inputName[index][1]\n",
    "        return img, id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputName)\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(size=128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def save_checkpoint(ckpt_path, model, optimizer):\n",
    "    state = {'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict': optimizer.state_dict(),}\n",
    "    torch.save(state, ckpt_path)\n",
    "\n",
    "def load_checkpoint(ckpt_path, device=device):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    return ckpt\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Couch00015.jpg', 13)\n",
      "('Fork00005.jpg', 24)\n",
      "# images in trainset: 3951\n",
      "# images in validset: 406\n"
     ]
    }
   ],
   "source": [
    "trainDS = dataset(inputPath=train_path, csvPath=train_csv, label2idPath=label2id_path, transform=img_transform)\n",
    "trainLoader = DataLoader(dataset=trainDS, batch_size=train_bz, shuffle=True, num_workers=4)\n",
    "validDS = dataset(inputPath=valid_path, csvPath=valid_csv, label2idPath=label2id_path, transform=img_transform)\n",
    "validLoader = DataLoader(dataset=validDS, batch_size=valid_bz, shuffle=False, num_workers=1)\n",
    "print('# images in trainset:', len(trainDS))\n",
    "print('# images in validset:', len(validDS))\n",
    "\n",
    "# dataiter = iter(validLoader)\n",
    "# images, labels = dataiter.next()\n",
    "# # print(labels)\n",
    "# print('Image tensor in each batch:', images.shape, images.dtype)\n",
    "# print('Label tensor in each batch:', labels.shape, labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class settingE(nn.Module):\n",
    "    def __init__(self, ckpt_path=None) -> None:\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(weights=None)\n",
    "        ckpt = load_checkpoint(ckpt_path, device)\n",
    "        self.resnet.load_state_dict(ckpt['model_state_dict'])\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(self.resnet.fc.out_features, 65)\n",
    "        # )\n",
    "        self.classifier = nn.Linear(2048, 65)\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x).flatten(1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainning\n",
    "def train(model, epochs):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,100], gamma=0.2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_acc = 0.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()        \n",
    "        train_loss, valid_loss = 0, 0\n",
    "        train_acc, valid_acc = 0, 0\n",
    "        for i, (img, label) in enumerate(trainLoader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img)\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            train_acc += pred.eq(label.view_as(pred)).sum().item()\n",
    "            loss = criterion(output, label)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()                \n",
    "        scheduler.step()\n",
    "        train_loss /= (i+1)\n",
    "        train_acc /= len(trainLoader.dataset)\n",
    "        print(\"Epoch: {:02}\".format(epoch))\n",
    "        print(\" | train_loss: {:6f}, train_acc: {:.2%}\".format(train_loss, train_acc))\n",
    "        model.eval()\n",
    "        with torch.no_grad(): # This will free the GPU memory used for back-prop\n",
    "            for i, (img, label) in enumerate(validLoader):\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                output = model(img)\n",
    "                valid_loss += criterion(output, label).item() # sum up batch loss\n",
    "                pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                valid_acc += pred.eq(label.view_as(pred)).sum().item()\n",
    "                # resultClass = torch.argmax(output, dim=1)\n",
    "                # acc += (resultClass == target).sum()\n",
    "            valid_loss /= (i+1)\n",
    "            valid_acc /= len(validLoader.dataset)\n",
    "        \n",
    "        save_checkpoint(os.path.join(ckpt_path, \"settingE_last.pth\"), model, optimizer)\n",
    "        print(\" | valid_loss: {:6f}, valid_acc: {:.2%}\".format(valid_loss, valid_acc))\n",
    "        \n",
    "        if valid_acc > best_acc:\n",
    "            save_checkpoint(os.path.join(ckpt_path, \"settingE_best.pth\"), model, optimizer)\n",
    "            print(\"  -> Save checkpoint for epoch {}\".format(epoch+1))\n",
    "            best_acc = valid_acc\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00\n",
      " | train_loss: 7.134433, train_acc: 12.53%\n",
      " | valid_loss: 3.759813, valid_acc: 20.44%\n",
      "  -> Save checkpoint for epoch 1\n",
      "Epoch: 01\n",
      " | train_loss: 3.099022, train_acc: 28.85%\n",
      " | valid_loss: 3.490430, valid_acc: 26.60%\n",
      "  -> Save checkpoint for epoch 2\n",
      "Epoch: 02\n",
      " | train_loss: 2.532619, train_acc: 35.03%\n",
      " | valid_loss: 3.514706, valid_acc: 28.08%\n",
      "  -> Save checkpoint for epoch 3\n",
      "Epoch: 03\n",
      " | train_loss: 2.398910, train_acc: 37.81%\n",
      " | valid_loss: 3.033623, valid_acc: 30.79%\n",
      "  -> Save checkpoint for epoch 4\n",
      "Epoch: 04\n",
      " | train_loss: 2.168164, train_acc: 42.55%\n",
      " | valid_loss: 3.044958, valid_acc: 29.31%\n",
      "Epoch: 05\n",
      " | train_loss: 2.083869, train_acc: 44.44%\n",
      " | valid_loss: 3.077753, valid_acc: 32.27%\n",
      "  -> Save checkpoint for epoch 6\n",
      "Epoch: 06\n",
      " | train_loss: 1.903793, train_acc: 47.38%\n",
      " | valid_loss: 2.409817, valid_acc: 29.80%\n",
      "Epoch: 07\n",
      " | train_loss: 1.785059, train_acc: 51.03%\n",
      " | valid_loss: 3.166905, valid_acc: 34.24%\n",
      "  -> Save checkpoint for epoch 8\n",
      "Epoch: 08\n",
      " | train_loss: 1.628701, train_acc: 53.78%\n",
      " | valid_loss: 3.113638, valid_acc: 31.53%\n",
      "Epoch: 09\n",
      " | train_loss: 1.566922, train_acc: 55.13%\n",
      " | valid_loss: 3.285906, valid_acc: 32.27%\n",
      "Epoch: 10\n",
      " | train_loss: 1.499880, train_acc: 56.04%\n",
      " | valid_loss: 2.803456, valid_acc: 34.48%\n",
      "  -> Save checkpoint for epoch 11\n",
      "Epoch: 11\n",
      " | train_loss: 1.413931, train_acc: 58.42%\n",
      " | valid_loss: 4.933293, valid_acc: 31.28%\n",
      "Epoch: 12\n",
      " | train_loss: 1.426267, train_acc: 58.74%\n",
      " | valid_loss: 2.674698, valid_acc: 34.48%\n",
      "Epoch: 13\n",
      " | train_loss: 1.320801, train_acc: 60.59%\n",
      " | valid_loss: 3.469896, valid_acc: 32.51%\n",
      "Epoch: 14\n",
      " | train_loss: 1.270673, train_acc: 62.26%\n",
      " | valid_loss: 2.708112, valid_acc: 34.24%\n",
      "Epoch: 15\n",
      " | train_loss: 1.207926, train_acc: 64.95%\n",
      " | valid_loss: 4.431070, valid_acc: 33.25%\n",
      "Epoch: 16\n",
      " | train_loss: 1.059815, train_acc: 68.36%\n",
      " | valid_loss: 3.414340, valid_acc: 35.71%\n",
      "  -> Save checkpoint for epoch 17\n",
      "Epoch: 17\n",
      " | train_loss: 1.139807, train_acc: 66.97%\n",
      " | valid_loss: 4.027905, valid_acc: 34.73%\n",
      "Epoch: 18\n",
      " | train_loss: 1.105481, train_acc: 67.07%\n",
      " | valid_loss: 3.240380, valid_acc: 38.42%\n",
      "  -> Save checkpoint for epoch 19\n",
      "Epoch: 19\n",
      " | train_loss: 1.041881, train_acc: 69.96%\n",
      " | valid_loss: 3.806977, valid_acc: 33.74%\n",
      "Epoch: 20\n",
      " | train_loss: 0.987629, train_acc: 69.96%\n",
      " | valid_loss: 2.728008, valid_acc: 33.99%\n",
      "Epoch: 21\n",
      " | train_loss: 0.902888, train_acc: 72.74%\n",
      " | valid_loss: 2.776156, valid_acc: 31.77%\n",
      "Epoch: 22\n",
      " | train_loss: 0.872726, train_acc: 73.60%\n",
      " | valid_loss: 3.190205, valid_acc: 36.95%\n",
      "Epoch: 23\n",
      " | train_loss: 0.828458, train_acc: 76.21%\n",
      " | valid_loss: 3.503419, valid_acc: 35.47%\n",
      "Epoch: 24\n",
      " | train_loss: 0.845458, train_acc: 74.87%\n",
      " | valid_loss: 3.097328, valid_acc: 37.44%\n",
      "Epoch: 25\n",
      " | train_loss: 0.807361, train_acc: 75.80%\n",
      " | valid_loss: 3.776242, valid_acc: 32.27%\n",
      "Epoch: 26\n",
      " | train_loss: 0.766208, train_acc: 76.23%\n",
      " | valid_loss: 4.253901, valid_acc: 35.96%\n",
      "Epoch: 27\n",
      " | train_loss: 0.785254, train_acc: 76.41%\n",
      " | valid_loss: 3.638257, valid_acc: 32.02%\n",
      "Epoch: 28\n",
      " | train_loss: 0.706719, train_acc: 78.84%\n",
      " | valid_loss: 3.615759, valid_acc: 34.24%\n",
      "Epoch: 29\n",
      " | train_loss: 0.684857, train_acc: 78.92%\n",
      " | valid_loss: 3.573287, valid_acc: 37.19%\n",
      "Epoch: 30\n",
      " | train_loss: 0.409249, train_acc: 89.57%\n",
      " | valid_loss: 3.170508, valid_acc: 39.90%\n",
      "  -> Save checkpoint for epoch 31\n",
      "Epoch: 31\n",
      " | train_loss: 0.352599, train_acc: 92.33%\n",
      " | valid_loss: 3.218052, valid_acc: 39.16%\n",
      "Epoch: 32\n",
      " | train_loss: 0.322231, train_acc: 94.05%\n",
      " | valid_loss: 3.309811, valid_acc: 38.92%\n",
      "Epoch: 33\n",
      " | train_loss: 0.321967, train_acc: 94.03%\n",
      " | valid_loss: 3.323348, valid_acc: 39.41%\n",
      "Epoch: 34\n",
      " | train_loss: 0.318504, train_acc: 94.13%\n",
      " | valid_loss: 3.232573, valid_acc: 39.16%\n",
      "Epoch: 35\n",
      " | train_loss: 0.315295, train_acc: 94.13%\n",
      " | valid_loss: 3.327718, valid_acc: 38.18%\n",
      "Epoch: 36\n",
      " | train_loss: 0.319205, train_acc: 94.08%\n",
      " | valid_loss: 3.113967, valid_acc: 40.39%\n",
      "  -> Save checkpoint for epoch 37\n",
      "Epoch: 37\n",
      " | train_loss: 0.315523, train_acc: 94.20%\n",
      " | valid_loss: 3.147835, valid_acc: 37.68%\n",
      "Epoch: 38\n",
      " | train_loss: 0.310579, train_acc: 94.48%\n",
      " | valid_loss: 3.165207, valid_acc: 38.18%\n",
      "Epoch: 39\n",
      " | train_loss: 0.302002, train_acc: 94.68%\n",
      " | valid_loss: 3.124182, valid_acc: 40.15%\n",
      "Epoch: 40\n",
      " | train_loss: 0.299678, train_acc: 94.79%\n",
      " | valid_loss: 3.209712, valid_acc: 40.15%\n",
      "Epoch: 41\n",
      " | train_loss: 0.295911, train_acc: 95.17%\n",
      " | valid_loss: 3.193433, valid_acc: 38.18%\n",
      "Epoch: 42\n",
      " | train_loss: 0.295372, train_acc: 94.79%\n",
      " | valid_loss: 3.236860, valid_acc: 38.92%\n",
      "Epoch: 43\n",
      " | train_loss: 0.294608, train_acc: 95.12%\n",
      " | valid_loss: 3.132377, valid_acc: 38.18%\n",
      "Epoch: 44\n",
      " | train_loss: 0.292211, train_acc: 95.04%\n",
      " | valid_loss: 3.099837, valid_acc: 37.93%\n",
      "Epoch: 45\n",
      " | train_loss: 0.287231, train_acc: 95.22%\n",
      " | valid_loss: 2.997567, valid_acc: 40.39%\n",
      "Epoch: 46\n",
      " | train_loss: 0.304277, train_acc: 94.31%\n",
      " | valid_loss: 3.238622, valid_acc: 39.16%\n",
      "Epoch: 47\n",
      " | train_loss: 0.284081, train_acc: 95.34%\n",
      " | valid_loss: 3.114582, valid_acc: 39.41%\n",
      "Epoch: 48\n",
      " | train_loss: 0.283611, train_acc: 95.29%\n",
      " | valid_loss: 3.127933, valid_acc: 38.92%\n",
      "Epoch: 49\n",
      " | train_loss: 0.281109, train_acc: 95.17%\n",
      " | valid_loss: 3.278447, valid_acc: 38.92%\n"
     ]
    }
   ],
   "source": [
    "model = settingE(ckpt_path=pretrained_path).to(device)\n",
    "# print(model)\n",
    "train(model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_model = settingE(retrain_path).to(device)\n",
    "# print(retrain_model)\n",
    "train(retrain_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de9865ccda6098b078ef1392bd6ff1290889aa8c91ce4253d5043d68b8c8de9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
