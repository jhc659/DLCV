{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json \n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "from byol_pytorch import BYOL\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/data/dlcv/hw4/office/train\"\n",
    "valid_path = \"/data/dlcv/hw4/office/val\"\n",
    "train_csv = \"/data/dlcv/hw4/office/train.csv\"\n",
    "valid_csv = \"/data/dlcv/hw4/office/val.csv\"\n",
    "label2id_path = \"./label2id.json\"\n",
    "ckpt_path = \"./ckpt/finetune\"\n",
    "pretrained_path = \"/data/dlcv/hw4/pretrain_model_SL.pt\"\n",
    "os.makedirs(ckpt_path, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(3)\n",
    "print('Device used:', device)\n",
    "\n",
    "img_size = 128\n",
    "train_bz = 64\n",
    "valid_bz = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, inputPath, csvPath, label2idPath, transform=None):\n",
    "        self.inputPath = inputPath\n",
    "        self.transform = transform\n",
    "        with open(label2idPath, 'r') as j:\n",
    "            self.label2id = json.loads(j.read())\n",
    "        self.inputName = []\n",
    "        df = pd.read_csv(csvPath)\n",
    "        for i in range(len(df)):\n",
    "            self.inputName.append((df.loc[i].filename, self.label2id[df.loc[i].label]))\n",
    "        print(self.inputName[0])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.inputPath, self.inputName[index][0]))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        id = self.inputName[index][1]\n",
    "        return img, id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputName)\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(size=128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def save_checkpoint(ckpt_path, model, optimizer):\n",
    "    state = {'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict': optimizer.state_dict(),}\n",
    "    torch.save(state, ckpt_path)\n",
    "\n",
    "def load_checkpoint(ckpt_path, device):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    return ckpt\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Couch00015.jpg', 13)\n",
      "('Fork00005.jpg', 24)\n",
      "# images in trainset: 3951\n",
      "# images in validset: 406\n"
     ]
    }
   ],
   "source": [
    "trainDS = dataset(inputPath=train_path, csvPath=train_csv, label2idPath=label2id_path, transform=img_transform)\n",
    "trainLoader = DataLoader(dataset=trainDS, batch_size=train_bz, shuffle=True, num_workers=4)\n",
    "validDS = dataset(inputPath=valid_path, csvPath=valid_csv, label2idPath=label2id_path, transform=img_transform)\n",
    "validLoader = DataLoader(dataset=validDS, batch_size=valid_bz, shuffle=False, num_workers=1)\n",
    "print('# images in trainset:', len(trainDS))\n",
    "print('# images in validset:', len(validDS))\n",
    "\n",
    "# dataiter = iter(validLoader)\n",
    "# images, labels = dataiter.next()\n",
    "# # print(labels)\n",
    "# print('Image tensor in each batch:', images.shape, images.dtype)\n",
    "# print('Label tensor in each batch:', labels.shape, labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class settingD(nn.Module):\n",
    "    def __init__(self, ckpt_path=None) -> None:\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(weights=None)\n",
    "        pretrained = torch.load(ckpt_path, map_location=device)\n",
    "        self.resnet.load_state_dict(pretrained)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(self.resnet.fc.out_features, 65)\n",
    "        # )\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.classifier = nn.Linear(2048, 65)\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x).flatten(1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainning\n",
    "def train(model, epochs):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,100], gamma=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_acc = 0.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()        \n",
    "        train_loss, valid_loss = 0, 0\n",
    "        train_acc, valid_acc = 0, 0\n",
    "        for i, (img, label) in enumerate(trainLoader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img)\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            train_acc += pred.eq(label.view_as(pred)).sum().item()\n",
    "            loss = criterion(output, label)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()                \n",
    "        scheduler.step()\n",
    "        train_loss /= (i+1)\n",
    "        train_acc /= len(trainLoader.dataset)\n",
    "        print(\"Epoch: {:02}\".format(epoch))\n",
    "        print(\" | train_loss: {:6f}, train_acc: {:.2%}\".format(train_loss, train_acc))\n",
    "        model.eval()\n",
    "        with torch.no_grad(): # This will free the GPU memory used for back-prop\n",
    "            for i, (img, label) in enumerate(validLoader):\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                output = model(img)\n",
    "                valid_loss += criterion(output, label).item() # sum up batch loss\n",
    "                pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                valid_acc += pred.eq(label.view_as(pred)).sum().item()\n",
    "                # resultClass = torch.argmax(output, dim=1)\n",
    "                # acc += (resultClass == target).sum()\n",
    "            valid_loss /= (i+1)\n",
    "            valid_acc /= len(validLoader.dataset)\n",
    "        \n",
    "        save_checkpoint(os.path.join(ckpt_path, \"settingD_last.pth\"), model, optimizer)\n",
    "        print(\" | valid_loss: {:6f}, train_acc: {:.2%}\".format(valid_loss, valid_acc))\n",
    "        \n",
    "        if valid_acc > best_acc:\n",
    "            save_checkpoint(os.path.join(ckpt_path, \"settingD_best.pth\"), model, optimizer)\n",
    "            print(\"  -> Save checkpoint for epoch {}\".format(epoch+1))\n",
    "            best_acc = valid_acc\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00\n",
      " | train_loss: 3.936221, train_acc: 10.38%\n",
      " | valid_loss: 3.619044, train_acc: 15.76%\n",
      "  -> Save checkpoint for epoch 1\n",
      "Epoch: 01\n",
      " | train_loss: 3.376216, train_acc: 24.17%\n",
      " | valid_loss: 3.326357, train_acc: 23.65%\n",
      "  -> Save checkpoint for epoch 2\n",
      "Epoch: 02\n",
      " | train_loss: 3.032767, train_acc: 31.79%\n",
      " | valid_loss: 3.013964, train_acc: 24.38%\n",
      "  -> Save checkpoint for epoch 3\n",
      "Epoch: 03\n",
      " | train_loss: 2.804058, train_acc: 36.67%\n",
      " | valid_loss: 3.044451, train_acc: 25.37%\n",
      "  -> Save checkpoint for epoch 4\n",
      "Epoch: 04\n",
      " | train_loss: 2.612007, train_acc: 41.03%\n",
      " | valid_loss: 2.975321, train_acc: 28.08%\n",
      "  -> Save checkpoint for epoch 5\n",
      "Epoch: 05\n",
      " | train_loss: 2.475687, train_acc: 43.25%\n",
      " | valid_loss: 2.762475, train_acc: 28.08%\n",
      "Epoch: 06\n",
      " | train_loss: 2.341510, train_acc: 46.75%\n",
      " | valid_loss: 2.745089, train_acc: 27.83%\n",
      "Epoch: 07\n",
      " | train_loss: 2.225117, train_acc: 49.43%\n",
      " | valid_loss: 2.714197, train_acc: 26.35%\n",
      "Epoch: 08\n",
      " | train_loss: 2.126283, train_acc: 52.16%\n",
      " | valid_loss: 2.521556, train_acc: 29.06%\n",
      "  -> Save checkpoint for epoch 9\n",
      "Epoch: 09\n",
      " | train_loss: 2.022507, train_acc: 54.06%\n",
      " | valid_loss: 2.655510, train_acc: 30.30%\n",
      "  -> Save checkpoint for epoch 10\n",
      "Epoch: 10\n",
      " | train_loss: 1.955929, train_acc: 56.57%\n",
      " | valid_loss: 2.659518, train_acc: 27.83%\n",
      "Epoch: 11\n",
      " | train_loss: 1.866141, train_acc: 58.87%\n",
      " | valid_loss: 2.640522, train_acc: 28.08%\n",
      "Epoch: 12\n",
      " | train_loss: 1.799122, train_acc: 61.30%\n",
      " | valid_loss: 2.689224, train_acc: 30.30%\n",
      "Epoch: 13\n",
      " | train_loss: 1.732402, train_acc: 62.44%\n",
      " | valid_loss: 2.572844, train_acc: 29.31%\n",
      "Epoch: 14\n",
      " | train_loss: 1.654309, train_acc: 64.54%\n",
      " | valid_loss: 2.713738, train_acc: 30.05%\n",
      "Epoch: 15\n",
      " | train_loss: 1.594288, train_acc: 65.93%\n",
      " | valid_loss: 2.463149, train_acc: 29.80%\n",
      "Epoch: 16\n",
      " | train_loss: 1.526070, train_acc: 69.00%\n",
      " | valid_loss: 2.706642, train_acc: 29.31%\n",
      "Epoch: 17\n",
      " | train_loss: 1.488351, train_acc: 69.83%\n",
      " | valid_loss: 2.612912, train_acc: 32.02%\n",
      "  -> Save checkpoint for epoch 18\n",
      "Epoch: 18\n",
      " | train_loss: 1.439054, train_acc: 71.86%\n",
      " | valid_loss: 2.672725, train_acc: 31.77%\n",
      "Epoch: 19\n",
      " | train_loss: 1.387347, train_acc: 72.23%\n",
      " | valid_loss: 2.495144, train_acc: 30.54%\n",
      "Epoch: 20\n",
      " | train_loss: 1.336454, train_acc: 75.55%\n",
      " | valid_loss: 2.561742, train_acc: 31.77%\n",
      "Epoch: 21\n",
      " | train_loss: 1.295926, train_acc: 75.53%\n",
      " | valid_loss: 2.543500, train_acc: 32.76%\n",
      "  -> Save checkpoint for epoch 22\n",
      "Epoch: 22\n",
      " | train_loss: 1.245208, train_acc: 76.79%\n",
      " | valid_loss: 2.598099, train_acc: 29.56%\n",
      "Epoch: 23\n",
      " | train_loss: 1.203328, train_acc: 79.30%\n",
      " | valid_loss: 2.509566, train_acc: 29.80%\n",
      "Epoch: 24\n",
      " | train_loss: 1.160146, train_acc: 80.23%\n",
      " | valid_loss: 2.657931, train_acc: 30.30%\n",
      "Epoch: 25\n",
      " | train_loss: 1.130238, train_acc: 80.79%\n",
      " | valid_loss: 2.493353, train_acc: 31.03%\n",
      "Epoch: 26\n",
      " | train_loss: 1.086705, train_acc: 81.73%\n",
      " | valid_loss: 2.549269, train_acc: 33.00%\n",
      "  -> Save checkpoint for epoch 27\n",
      "Epoch: 27\n",
      " | train_loss: 1.051236, train_acc: 83.47%\n",
      " | valid_loss: 2.503916, train_acc: 32.51%\n",
      "Epoch: 28\n",
      " | train_loss: 1.027736, train_acc: 83.80%\n",
      " | valid_loss: 2.681450, train_acc: 31.53%\n",
      "Epoch: 29\n",
      " | train_loss: 0.981543, train_acc: 85.27%\n",
      " | valid_loss: 2.502591, train_acc: 32.02%\n",
      "Epoch: 30\n",
      " | train_loss: 0.956153, train_acc: 86.89%\n",
      " | valid_loss: 2.604731, train_acc: 32.27%\n",
      "Epoch: 31\n",
      " | train_loss: 0.924099, train_acc: 86.91%\n",
      " | valid_loss: 2.467814, train_acc: 32.02%\n",
      "Epoch: 32\n",
      " | train_loss: 0.894857, train_acc: 87.90%\n",
      " | valid_loss: 2.652668, train_acc: 31.53%\n",
      "Epoch: 33\n",
      " | train_loss: 0.862563, train_acc: 88.86%\n",
      " | valid_loss: 2.461839, train_acc: 31.77%\n",
      "Epoch: 34\n",
      " | train_loss: 0.856139, train_acc: 88.84%\n",
      " | valid_loss: 2.486293, train_acc: 30.54%\n",
      "Epoch: 35\n",
      " | train_loss: 0.807529, train_acc: 90.69%\n",
      " | valid_loss: 2.506224, train_acc: 32.51%\n",
      "Epoch: 36\n",
      " | train_loss: 0.780525, train_acc: 90.33%\n",
      " | valid_loss: 2.519221, train_acc: 30.30%\n",
      "Epoch: 37\n",
      " | train_loss: 0.761186, train_acc: 90.94%\n",
      " | valid_loss: 2.592792, train_acc: 32.02%\n",
      "Epoch: 38\n",
      " | train_loss: 0.746291, train_acc: 92.18%\n",
      " | valid_loss: 2.528244, train_acc: 32.76%\n",
      "Epoch: 39\n",
      " | train_loss: 0.716353, train_acc: 92.66%\n",
      " | valid_loss: 2.562595, train_acc: 32.27%\n",
      "Epoch: 40\n",
      " | train_loss: 0.717403, train_acc: 92.46%\n",
      " | valid_loss: 2.532103, train_acc: 31.77%\n",
      "Epoch: 41\n",
      " | train_loss: 0.689186, train_acc: 93.27%\n",
      " | valid_loss: 2.495854, train_acc: 33.25%\n",
      "  -> Save checkpoint for epoch 42\n",
      "Epoch: 42\n",
      " | train_loss: 0.661884, train_acc: 93.60%\n",
      " | valid_loss: 2.538324, train_acc: 29.80%\n",
      "Epoch: 43\n",
      " | train_loss: 0.646592, train_acc: 94.10%\n",
      " | valid_loss: 2.536865, train_acc: 34.98%\n",
      "  -> Save checkpoint for epoch 44\n",
      "Epoch: 44\n",
      " | train_loss: 0.628057, train_acc: 94.25%\n",
      " | valid_loss: 2.552613, train_acc: 32.27%\n",
      "Epoch: 45\n",
      " | train_loss: 0.613457, train_acc: 94.58%\n",
      " | valid_loss: 2.599611, train_acc: 32.27%\n",
      "Epoch: 46\n",
      " | train_loss: 0.592874, train_acc: 95.19%\n",
      " | valid_loss: 2.388702, train_acc: 34.48%\n",
      "Epoch: 47\n",
      " | train_loss: 0.589389, train_acc: 95.57%\n",
      " | valid_loss: 2.468243, train_acc: 31.77%\n",
      "Epoch: 48\n",
      " | train_loss: 0.558055, train_acc: 95.82%\n",
      " | valid_loss: 2.463635, train_acc: 32.76%\n",
      "Epoch: 49\n",
      " | train_loss: 0.544686, train_acc: 96.05%\n",
      " | valid_loss: 2.448950, train_acc: 31.53%\n"
     ]
    }
   ],
   "source": [
    "model = settingD(ckpt_path=pretrained_path).to(device)\n",
    "# print(model)\n",
    "train(model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de9865ccda6098b078ef1392bd6ff1290889aa8c91ce4253d5043d68b8c8de9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
