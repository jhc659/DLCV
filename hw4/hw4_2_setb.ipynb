{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json \n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "from byol_pytorch import BYOL\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/data/dlcv/hw4/office/train\"\n",
    "valid_path = \"/data/dlcv/hw4/office/val\"\n",
    "train_csv = \"/data/dlcv/hw4/office/train.csv\"\n",
    "valid_csv = \"/data/dlcv/hw4/office/val.csv\"\n",
    "label2id_path = \"./label2id.json\"\n",
    "ckpt_path = \"./ckpt/finetune\"\n",
    "pretrained_path = \"/data/dlcv/hw4/pretrain_model_SL.pt\"\n",
    "os.makedirs(ckpt_path, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(3)\n",
    "print('Device used:', device)\n",
    "\n",
    "img_size = 128\n",
    "train_bz = 64\n",
    "valid_bz = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, inputPath, csvPath, label2idPath, transform=None):\n",
    "        self.inputPath = inputPath\n",
    "        self.transform = transform\n",
    "        with open(label2idPath, 'r') as j:\n",
    "            self.label2id = json.loads(j.read())\n",
    "        self.inputName = []\n",
    "        df = pd.read_csv(csvPath)\n",
    "        for i in range(len(df)):\n",
    "            self.inputName.append((df.loc[i].filename, self.label2id[df.loc[i].label]))\n",
    "        print(self.inputName[0])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.inputPath, self.inputName[index][0]))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        id = self.inputName[index][1]\n",
    "        return img, id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputName)\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(size=128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def save_checkpoint(ckpt_path, model, optimizer):\n",
    "    state = {'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict': optimizer.state_dict(),}\n",
    "    torch.save(state, ckpt_path)\n",
    "\n",
    "def load_checkpoint(ckpt_path, device):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    return ckpt\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Couch00015.jpg', 13)\n",
      "('Fork00005.jpg', 24)\n",
      "# images in trainset: 3951\n",
      "# images in validset: 406\n"
     ]
    }
   ],
   "source": [
    "trainDS = dataset(inputPath=train_path, csvPath=train_csv, label2idPath=label2id_path, transform=img_transform)\n",
    "trainLoader = DataLoader(dataset=trainDS, batch_size=train_bz, shuffle=True, num_workers=4)\n",
    "validDS = dataset(inputPath=valid_path, csvPath=valid_csv, label2idPath=label2id_path, transform=img_transform)\n",
    "validLoader = DataLoader(dataset=validDS, batch_size=valid_bz, shuffle=False, num_workers=1)\n",
    "print('# images in trainset:', len(trainDS))\n",
    "print('# images in validset:', len(validDS))\n",
    "\n",
    "# dataiter = iter(validLoader)\n",
    "# images, labels = dataiter.next()\n",
    "# # print(labels)\n",
    "# print('Image tensor in each batch:', images.shape, images.dtype)\n",
    "# print('Label tensor in each batch:', labels.shape, labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class settingB(nn.Module):\n",
    "    def __init__(self, ckpt_path=None) -> None:\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(weights=None)\n",
    "        pretrained = torch.load(ckpt_path, map_location=device)\n",
    "        self.resnet.load_state_dict(pretrained)\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(self.resnet.fc.out_features, 65)\n",
    "        # )\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.classifier = nn.Linear(2048, 65)\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x).flatten(1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainning\n",
    "def train(model, epochs):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,100], gamma=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_acc = 0.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()        \n",
    "        train_loss, valid_loss = 0, 0\n",
    "        train_acc, valid_acc = 0, 0\n",
    "        for i, (img, label) in enumerate(trainLoader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img)\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            train_acc += pred.eq(label.view_as(pred)).sum().item()\n",
    "            loss = criterion(output, label)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()                \n",
    "        scheduler.step()\n",
    "        train_loss /= (i+1)\n",
    "        train_acc /= len(trainLoader.dataset)\n",
    "        print(\"Epoch: {:02}\".format(epoch))\n",
    "        print(\" | train_loss: {:6f}, train_acc: {:.2%}\".format(train_loss, train_acc))\n",
    "        model.eval()\n",
    "        with torch.no_grad(): # This will free the GPU memory used for back-prop\n",
    "            for i, (img, label) in enumerate(validLoader):\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                output = model(img)\n",
    "                valid_loss += criterion(output, label).item() # sum up batch loss\n",
    "                pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                valid_acc += pred.eq(label.view_as(pred)).sum().item()\n",
    "                # resultClass = torch.argmax(output, dim=1)\n",
    "                # acc += (resultClass == target).sum()\n",
    "            valid_loss /= (i+1)\n",
    "            valid_acc /= len(validLoader.dataset)\n",
    "        \n",
    "        save_checkpoint(os.path.join(ckpt_path, \"settingB_last.pth\"), model, optimizer)\n",
    "        print(\" | valid_loss: {:6f}, train_acc: {:.2%}\".format(valid_loss, valid_acc))\n",
    "        \n",
    "        if valid_acc > best_acc:\n",
    "            save_checkpoint(os.path.join(ckpt_path, \"settingB_best.pth\"), model, optimizer)\n",
    "            print(\"  -> Save checkpoint for epoch {}\".format(epoch+1))\n",
    "            best_acc = valid_acc\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00\n",
      " | train_loss: 3.879607, train_acc: 8.63%\n",
      " | valid_loss: 4.378823, train_acc: 9.61%\n",
      "  -> Save checkpoint for epoch 1\n",
      "Epoch: 01\n",
      " | train_loss: 3.396489, train_acc: 15.92%\n",
      " | valid_loss: 3.832235, train_acc: 16.50%\n",
      "  -> Save checkpoint for epoch 2\n",
      "Epoch: 02\n",
      " | train_loss: 3.047138, train_acc: 23.03%\n",
      " | valid_loss: 3.175761, train_acc: 21.67%\n",
      "  -> Save checkpoint for epoch 3\n",
      "Epoch: 03\n",
      " | train_loss: 2.675387, train_acc: 30.35%\n",
      " | valid_loss: 3.280406, train_acc: 28.57%\n",
      "  -> Save checkpoint for epoch 4\n",
      "Epoch: 04\n",
      " | train_loss: 2.364651, train_acc: 35.69%\n",
      " | valid_loss: 3.161000, train_acc: 28.82%\n",
      "  -> Save checkpoint for epoch 5\n",
      "Epoch: 05\n",
      " | train_loss: 2.032221, train_acc: 44.82%\n",
      " | valid_loss: 2.727740, train_acc: 31.77%\n",
      "  -> Save checkpoint for epoch 6\n",
      "Epoch: 06\n",
      " | train_loss: 1.595208, train_acc: 54.90%\n",
      " | valid_loss: 2.805324, train_acc: 33.25%\n",
      "  -> Save checkpoint for epoch 7\n",
      "Epoch: 07\n",
      " | train_loss: 1.132917, train_acc: 67.22%\n",
      " | valid_loss: 3.138352, train_acc: 30.79%\n",
      "Epoch: 08\n",
      " | train_loss: 0.740185, train_acc: 78.13%\n",
      " | valid_loss: 3.577722, train_acc: 32.51%\n",
      "Epoch: 09\n",
      " | train_loss: 0.466716, train_acc: 86.21%\n",
      " | valid_loss: 3.844524, train_acc: 33.74%\n",
      "  -> Save checkpoint for epoch 10\n",
      "Epoch: 10\n",
      " | train_loss: 0.323204, train_acc: 90.41%\n",
      " | valid_loss: 3.464831, train_acc: 34.73%\n",
      "  -> Save checkpoint for epoch 11\n",
      "Epoch: 11\n",
      " | train_loss: 0.186091, train_acc: 95.32%\n",
      " | valid_loss: 4.049380, train_acc: 34.48%\n",
      "Epoch: 12\n",
      " | train_loss: 0.102601, train_acc: 97.62%\n",
      " | valid_loss: 4.002749, train_acc: 34.48%\n",
      "Epoch: 13\n",
      " | train_loss: 0.086043, train_acc: 98.18%\n",
      " | valid_loss: 3.962481, train_acc: 33.50%\n",
      "Epoch: 14\n",
      " | train_loss: 0.060170, train_acc: 98.66%\n",
      " | valid_loss: 3.941191, train_acc: 33.99%\n",
      "Epoch: 15\n",
      " | train_loss: 0.057761, train_acc: 98.73%\n",
      " | valid_loss: 4.530584, train_acc: 32.02%\n",
      "Epoch: 16\n",
      " | train_loss: 0.039162, train_acc: 99.16%\n",
      " | valid_loss: 4.330681, train_acc: 37.44%\n",
      "  -> Save checkpoint for epoch 17\n",
      "Epoch: 17\n",
      " | train_loss: 0.020711, train_acc: 99.44%\n",
      " | valid_loss: 4.293614, train_acc: 36.95%\n",
      "Epoch: 18\n",
      " | train_loss: 0.024375, train_acc: 99.19%\n",
      " | valid_loss: 4.934527, train_acc: 35.71%\n",
      "Epoch: 19\n",
      " | train_loss: 0.094081, train_acc: 96.96%\n",
      " | valid_loss: 4.861829, train_acc: 28.33%\n",
      "Epoch: 20\n",
      " | train_loss: 0.241513, train_acc: 92.76%\n",
      " | valid_loss: 3.662010, train_acc: 29.31%\n",
      "Epoch: 21\n",
      " | train_loss: 0.232632, train_acc: 92.79%\n",
      " | valid_loss: 4.286693, train_acc: 34.24%\n",
      "Epoch: 22\n",
      " | train_loss: 0.193550, train_acc: 94.00%\n",
      " | valid_loss: 3.919909, train_acc: 34.98%\n",
      "Epoch: 23\n",
      " | train_loss: 0.101714, train_acc: 97.01%\n",
      " | valid_loss: 3.487654, train_acc: 36.45%\n",
      "Epoch: 24\n",
      " | train_loss: 0.066416, train_acc: 98.23%\n",
      " | valid_loss: 3.787917, train_acc: 33.99%\n",
      "Epoch: 25\n",
      " | train_loss: 0.046908, train_acc: 98.76%\n",
      " | valid_loss: 3.676795, train_acc: 35.71%\n",
      "Epoch: 26\n",
      " | train_loss: 0.021745, train_acc: 99.34%\n",
      " | valid_loss: 3.671434, train_acc: 37.44%\n",
      "Epoch: 27\n",
      " | train_loss: 0.018821, train_acc: 99.32%\n",
      " | valid_loss: 3.928200, train_acc: 36.21%\n",
      "Epoch: 28\n",
      " | train_loss: 0.012152, train_acc: 99.44%\n",
      " | valid_loss: 3.832888, train_acc: 38.67%\n",
      "  -> Save checkpoint for epoch 29\n",
      "Epoch: 29\n",
      " | train_loss: 0.013299, train_acc: 99.32%\n",
      " | valid_loss: 3.830373, train_acc: 37.19%\n",
      "Epoch: 30\n",
      " | train_loss: 0.010820, train_acc: 99.24%\n",
      " | valid_loss: 4.044969, train_acc: 38.67%\n",
      "Epoch: 31\n",
      " | train_loss: 0.010201, train_acc: 99.49%\n",
      " | valid_loss: 4.036778, train_acc: 36.95%\n",
      "Epoch: 32\n",
      " | train_loss: 0.009424, train_acc: 99.47%\n",
      " | valid_loss: 4.046832, train_acc: 37.19%\n",
      "Epoch: 33\n",
      " | train_loss: 0.009080, train_acc: 99.44%\n",
      " | valid_loss: 4.058637, train_acc: 37.68%\n",
      "Epoch: 34\n",
      " | train_loss: 0.008342, train_acc: 99.42%\n",
      " | valid_loss: 4.106212, train_acc: 37.93%\n",
      "Epoch: 35\n",
      " | train_loss: 0.008456, train_acc: 99.39%\n",
      " | valid_loss: 4.080461, train_acc: 37.44%\n",
      "Epoch: 36\n",
      " | train_loss: 0.008398, train_acc: 99.47%\n",
      " | valid_loss: 4.173296, train_acc: 37.19%\n",
      "Epoch: 37\n",
      " | train_loss: 0.007979, train_acc: 99.49%\n",
      " | valid_loss: 4.212162, train_acc: 37.68%\n",
      "Epoch: 38\n",
      " | train_loss: 0.009122, train_acc: 99.39%\n",
      " | valid_loss: 4.205906, train_acc: 37.68%\n",
      "Epoch: 39\n",
      " | train_loss: 0.008812, train_acc: 99.32%\n",
      " | valid_loss: 4.197015, train_acc: 35.96%\n",
      "Epoch: 40\n",
      " | train_loss: 0.008104, train_acc: 99.49%\n",
      " | valid_loss: 4.233915, train_acc: 38.18%\n",
      "Epoch: 41\n",
      " | train_loss: 0.008350, train_acc: 99.39%\n",
      " | valid_loss: 4.171568, train_acc: 37.19%\n",
      "Epoch: 42\n",
      " | train_loss: 0.008167, train_acc: 99.44%\n",
      " | valid_loss: 4.203159, train_acc: 37.44%\n",
      "Epoch: 43\n",
      " | train_loss: 0.007866, train_acc: 99.57%\n",
      " | valid_loss: 4.172582, train_acc: 37.93%\n",
      "Epoch: 44\n",
      " | train_loss: 0.007916, train_acc: 99.52%\n",
      " | valid_loss: 4.230514, train_acc: 37.68%\n",
      "Epoch: 45\n",
      " | train_loss: 0.007775, train_acc: 99.52%\n",
      " | valid_loss: 4.234708, train_acc: 37.19%\n",
      "Epoch: 46\n",
      " | train_loss: 0.007880, train_acc: 99.47%\n",
      " | valid_loss: 4.276013, train_acc: 37.44%\n",
      "Epoch: 47\n",
      " | train_loss: 0.007727, train_acc: 99.52%\n",
      " | valid_loss: 4.263835, train_acc: 37.19%\n",
      "Epoch: 48\n",
      " | train_loss: 0.007247, train_acc: 99.44%\n",
      " | valid_loss: 4.369909, train_acc: 38.18%\n",
      "Epoch: 49\n",
      " | train_loss: 0.007772, train_acc: 99.52%\n",
      " | valid_loss: 4.286550, train_acc: 37.93%\n"
     ]
    }
   ],
   "source": [
    "model = settingB(ckpt_path=pretrained_path).to(device)\n",
    "# print(model)\n",
    "train(model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de9865ccda6098b078ef1392bd6ff1290889aa8c91ce4253d5043d68b8c8de9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
