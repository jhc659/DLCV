{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json \n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "from byol_pytorch import BYOL\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/data/dlcv/hw4/office/train\"\n",
    "valid_path = \"/data/dlcv/hw4/office/val\"\n",
    "train_csv = \"/data/dlcv/hw4/office/train.csv\"\n",
    "valid_csv = \"/data/dlcv/hw4/office/val.csv\"\n",
    "label2id_path = \"./label2id.json\"\n",
    "ckpt_path = \"./ckpt/finetune\"\n",
    "os.makedirs(ckpt_path, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(4)\n",
    "print('Device used:', device)\n",
    "\n",
    "img_size = 128\n",
    "train_bz = 64\n",
    "valid_bz = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Couch']\n",
      "[0]\n",
      "Couch\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(train_csv)\n",
    "print(df.loc[df['filename']==\"Couch00015.jpg\"]['label'].to_list())\n",
    "print(df.index[df['filename']==\"Couch00015.jpg\"].to_list())\n",
    "print(df['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"/data/jhccc/dlcv/hw4-jhc659/label2id.json\", 'r') as j:\n",
    "    label2id = json.loads(j.read())\n",
    "print(type(label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refrigerator\n"
     ]
    }
   ],
   "source": [
    "# label = df.loc[df['filename']==\"Couch00015.jpg\"].label\n",
    "label = df.loc[2].label\n",
    "\n",
    "print(label)\n",
    "# print(label2id[label[0]])\n",
    "# print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, inputPath, csvPath, label2idPath, transform=None):\n",
    "        self.inputPath = inputPath\n",
    "        self.transform = transform\n",
    "        with open(label2idPath, 'r') as j:\n",
    "            self.label2id = json.loads(j.read())\n",
    "        self.inputName = []\n",
    "        df = pd.read_csv(csvPath)\n",
    "        for i in range(len(df)):\n",
    "            self.inputName.append((df.loc[i].filename, self.label2id[df.loc[i].label]))\n",
    "        print(self.inputName[0])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.inputPath, self.inputName[index][0]))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        id = self.inputName[index][1]\n",
    "        return img, id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputName)\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(size=128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def save_checkpoint(ckpt_path, model, optimizer):\n",
    "    state = {'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict': optimizer.state_dict(),}\n",
    "    torch.save(state, ckpt_path)\n",
    "\n",
    "def load_checkpoint(ckpt_path, device):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    return ckpt\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Couch00015.jpg', 13)\n",
      "('Fork00005.jpg', 24)\n",
      "# images in trainset: 3951\n",
      "# images in validset: 406\n"
     ]
    }
   ],
   "source": [
    "trainDS = dataset(inputPath=train_path, csvPath=train_csv, label2idPath=label2id_path, transform=img_transform)\n",
    "trainLoader = DataLoader(dataset=trainDS, batch_size=train_bz, shuffle=True, num_workers=4)\n",
    "validDS = dataset(inputPath=valid_path, csvPath=valid_csv, label2idPath=label2id_path, transform=img_transform)\n",
    "validLoader = DataLoader(dataset=validDS, batch_size=valid_bz, shuffle=False, num_workers=1)\n",
    "print('# images in trainset:', len(trainDS))\n",
    "print('# images in validset:', len(validDS))\n",
    "\n",
    "# dataiter = iter(validLoader)\n",
    "# images, labels = dataiter.next()\n",
    "# # print(labels)\n",
    "# print('Image tensor in each batch:', images.shape, images.dtype)\n",
    "# print('Label tensor in each batch:', labels.shape, labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class settingA(nn.Module):\n",
    "    def __init__(self, ckpt_path=None) -> None:\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(weights=None)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.out_features, 65)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainning\n",
    "def train(model, epochs):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,100], gamma=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_acc = 0.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()        \n",
    "        train_loss, valid_loss = 0, 0\n",
    "        train_acc, valid_acc = 0, 0\n",
    "        for i, (img, label) in enumerate(trainLoader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img)\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            train_acc += pred.eq(label.view_as(pred)).sum().item()\n",
    "            loss = criterion(output, label)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()                \n",
    "        scheduler.step()\n",
    "        train_loss /= (i+1)\n",
    "        train_acc /= len(trainLoader.dataset)\n",
    "        print(\"Epoch: {:02}\".format(epoch))\n",
    "        print(\" |train_loss: {:6f}, train_acc: {:.2%}\".format(train_loss, train_acc))\n",
    "        model.eval()\n",
    "        with torch.no_grad(): # This will free the GPU memory used for back-prop\n",
    "            for i, (img, label) in enumerate(validLoader):\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                output = model(img)\n",
    "                valid_loss += criterion(output, label).item() # sum up batch loss\n",
    "                pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                valid_acc += pred.eq(label.view_as(pred)).sum().item()\n",
    "                # resultClass = torch.argmax(output, dim=1)\n",
    "                # acc += (resultClass == target).sum()\n",
    "            valid_loss /= (i+1)\n",
    "            valid_acc /= len(validLoader.dataset)\n",
    "\n",
    "        if valid_acc > best_acc:\n",
    "            save_checkpoint(os.path.join(ckpt_path, \"settingA_best.pth\"), model, optimizer)\n",
    "            print(\"| Save checkpoint for epoch {}\".format(epoch+1))\n",
    "            \n",
    "            best_acc = valid_acc\n",
    "        save_checkpoint(os.path.join(ckpt_path, \"settingA_last.pth\"), model, optimizer)\n",
    "        print(\" |valid_loss: {:6f}, train_acc: {:.2%}\".format(valid_loss, valid_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00\n",
      " |train_loss: 5.881514, train_acc: 1.92%\n",
      "| Save checkpoint for epoch 1\n",
      " |valid_loss: 6.023097, train_acc: 2.71%\n",
      "Epoch: 01\n",
      " |train_loss: 4.144563, train_acc: 2.28%\n",
      " |valid_loss: 4.162073, train_acc: 2.22%\n",
      "Epoch: 02\n",
      " |train_loss: 4.081208, train_acc: 3.47%\n",
      "| Save checkpoint for epoch 3\n",
      " |valid_loss: 4.103574, train_acc: 5.91%\n",
      "Epoch: 03\n",
      " |train_loss: 3.987463, train_acc: 4.88%\n",
      " |valid_loss: 3.887041, train_acc: 4.68%\n",
      "Epoch: 04\n",
      " |train_loss: 3.919579, train_acc: 5.47%\n",
      " |valid_loss: 4.189121, train_acc: 5.91%\n",
      "Epoch: 05\n",
      " |train_loss: 3.872905, train_acc: 6.28%\n",
      "| Save checkpoint for epoch 6\n",
      " |valid_loss: 3.929351, train_acc: 8.62%\n",
      "Epoch: 06\n",
      " |train_loss: 3.810718, train_acc: 7.29%\n",
      " |valid_loss: 3.773169, train_acc: 8.37%\n",
      "Epoch: 07\n",
      " |train_loss: 3.740709, train_acc: 8.15%\n",
      "| Save checkpoint for epoch 8\n",
      " |valid_loss: 3.785695, train_acc: 9.11%\n",
      "Epoch: 08\n",
      " |train_loss: 3.696111, train_acc: 9.34%\n",
      " |valid_loss: 3.824679, train_acc: 7.14%\n",
      "Epoch: 09\n",
      " |train_loss: 3.647703, train_acc: 10.15%\n",
      "| Save checkpoint for epoch 10\n",
      " |valid_loss: 3.817697, train_acc: 9.85%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/jhccc/dlcv/hw4-jhc659/hw4_2_a.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.112.29.93/data/jhccc/dlcv/hw4-jhc659/hw4_2_a.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m settingA()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B140.112.29.93/data/jhccc/dlcv/hw4-jhc659/hw4_2_a.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m train(model, \u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/data/jhccc/dlcv/hw4-jhc659/hw4_2_a.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.112.29.93/data/jhccc/dlcv/hw4-jhc659/hw4_2_a.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m train_loss, valid_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.112.29.93/data/jhccc/dlcv/hw4-jhc659/hw4_2_a.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m train_acc, valid_acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B140.112.29.93/data/jhccc/dlcv/hw4-jhc659/hw4_2_a.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (img, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainLoader):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.112.29.93/data/jhccc/dlcv/hw4-jhc659/hw4_2_a.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     img, label \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mto(device), label\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.112.29.93/data/jhccc/dlcv/hw4-jhc659/hw4_2_a.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1326\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1164\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = settingA().to(device)\n",
    "train(model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de9865ccda6098b078ef1392bd6ff1290889aa8c91ce4253d5043d68b8c8de9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
