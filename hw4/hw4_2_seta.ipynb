{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json \n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "from byol_pytorch import BYOL\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/data/dlcv/hw4/office/train\"\n",
    "valid_path = \"/data/dlcv/hw4/office/val\"\n",
    "train_csv = \"/data/dlcv/hw4/office/train.csv\"\n",
    "valid_csv = \"/data/dlcv/hw4/office/val.csv\"\n",
    "label2id_path = \"./label2id.json\"\n",
    "ckpt_path = \"./ckpt/finetune\"\n",
    "os.makedirs(ckpt_path, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(3)\n",
    "print('Device used:', device)\n",
    "\n",
    "img_size = 128\n",
    "train_bz = 64\n",
    "valid_bz = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Couch']\n",
      "[0]\n",
      "Couch\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(train_csv)\n",
    "print(df.loc[df['filename']==\"Couch00015.jpg\"]['label'].to_list())\n",
    "print(df.index[df['filename']==\"Couch00015.jpg\"].to_list())\n",
    "print(df['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"/data/jhccc/dlcv/hw4-jhc659/label2id.json\", 'r') as j:\n",
    "    label2id = json.loads(j.read())\n",
    "print(type(label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refrigerator\n"
     ]
    }
   ],
   "source": [
    "# label = df.loc[df['filename']==\"Couch00015.jpg\"].label\n",
    "label = df.loc[2].label\n",
    "\n",
    "print(label)\n",
    "# print(label2id[label[0]])\n",
    "# print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, inputPath, csvPath, label2idPath, transform=None):\n",
    "        self.inputPath = inputPath\n",
    "        self.transform = transform\n",
    "        with open(label2idPath, 'r') as j:\n",
    "            self.label2id = json.loads(j.read())\n",
    "        self.inputName = []\n",
    "        df = pd.read_csv(csvPath)\n",
    "        for i in range(len(df)):\n",
    "            self.inputName.append((df.loc[i].filename, self.label2id[df.loc[i].label]))\n",
    "        print(self.inputName[0])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.inputPath, self.inputName[index][0]))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        id = self.inputName[index][1]\n",
    "        return img, id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputName)\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(size=128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def save_checkpoint(ckpt_path, model, optimizer):\n",
    "    state = {'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict': optimizer.state_dict(),}\n",
    "    torch.save(state, ckpt_path)\n",
    "\n",
    "def load_checkpoint(ckpt_path, device):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    return ckpt\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Couch00015.jpg', 13)\n",
      "('Fork00005.jpg', 24)\n",
      "# images in trainset: 3951\n",
      "# images in validset: 406\n"
     ]
    }
   ],
   "source": [
    "trainDS = dataset(inputPath=train_path, csvPath=train_csv, label2idPath=label2id_path, transform=img_transform)\n",
    "trainLoader = DataLoader(dataset=trainDS, batch_size=train_bz, shuffle=True, num_workers=4)\n",
    "validDS = dataset(inputPath=valid_path, csvPath=valid_csv, label2idPath=label2id_path, transform=img_transform)\n",
    "validLoader = DataLoader(dataset=validDS, batch_size=valid_bz, shuffle=False, num_workers=1)\n",
    "print('# images in trainset:', len(trainDS))\n",
    "print('# images in validset:', len(validDS))\n",
    "\n",
    "# dataiter = iter(validLoader)\n",
    "# images, labels = dataiter.next()\n",
    "# # print(labels)\n",
    "# print('Image tensor in each batch:', images.shape, images.dtype)\n",
    "# print('Label tensor in each batch:', labels.shape, labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class settingA(nn.Module):\n",
    "    def __init__(self, ckpt_path=None) -> None:\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(weights=None)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.classifier = nn.Linear(2048, 65)\n",
    "        \n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(self.resnet.fc.out_features, 65)\n",
    "        # )\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x).flatten(1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainning\n",
    "def train(model, epochs):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,100], gamma=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_acc = 0.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()        \n",
    "        train_loss, valid_loss = 0, 0\n",
    "        train_acc, valid_acc = 0, 0\n",
    "        for i, (img, label) in enumerate(trainLoader):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img)\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            train_acc += pred.eq(label.view_as(pred)).sum().item()\n",
    "            loss = criterion(output, label)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()                \n",
    "        scheduler.step()\n",
    "        train_loss /= (i+1)\n",
    "        train_acc /= len(trainLoader.dataset)\n",
    "        print(\"Epoch: {:02}\".format(epoch))\n",
    "        print(\" | train_loss: {:6f}, train_acc: {:.2%}\".format(train_loss, train_acc))\n",
    "        model.eval()\n",
    "        with torch.no_grad(): # This will free the GPU memory used for back-prop\n",
    "            for i, (img, label) in enumerate(validLoader):\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                output = model(img)\n",
    "                valid_loss += criterion(output, label).item() # sum up batch loss\n",
    "                pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                valid_acc += pred.eq(label.view_as(pred)).sum().item()\n",
    "                # resultClass = torch.argmax(output, dim=1)\n",
    "                # acc += (resultClass == target).sum()\n",
    "            valid_loss /= (i+1)\n",
    "            valid_acc /= len(validLoader.dataset)\n",
    "\n",
    "        if valid_acc > best_acc:\n",
    "            save_checkpoint(os.path.join(ckpt_path, \"settingA_best.pth\"), model, optimizer)\n",
    "            print(\"  -> Save checkpoint for epoch {}\".format(epoch+1))\n",
    "            \n",
    "            best_acc = valid_acc\n",
    "        save_checkpoint(os.path.join(ckpt_path, \"settingA_last.pth\"), model, optimizer)\n",
    "        print(\" | valid_loss: {:6f}, train_acc: {:.2%}\".format(valid_loss, valid_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00\n",
      " | train_loss: 4.941247, train_acc: 2.10%\n",
      "  -> Save checkpoint for epoch 1\n",
      " | valid_loss: 4.007800, train_acc: 3.94%\n",
      "Epoch: 01\n",
      " | train_loss: 4.124408, train_acc: 5.44%\n",
      "  -> Save checkpoint for epoch 2\n",
      " | valid_loss: 4.132324, train_acc: 7.14%\n",
      "Epoch: 02\n",
      " | train_loss: 3.910314, train_acc: 6.93%\n",
      " | valid_loss: 3.911017, train_acc: 7.14%\n",
      "Epoch: 03\n",
      " | train_loss: 3.833807, train_acc: 8.30%\n",
      "  -> Save checkpoint for epoch 4\n",
      " | valid_loss: 3.864118, train_acc: 7.39%\n",
      "Epoch: 04\n",
      " | train_loss: 3.736766, train_acc: 10.20%\n",
      "  -> Save checkpoint for epoch 5\n",
      " | valid_loss: 3.918081, train_acc: 9.36%\n",
      "Epoch: 05\n",
      " | train_loss: 3.685013, train_acc: 10.71%\n",
      "  -> Save checkpoint for epoch 6\n",
      " | valid_loss: 3.663734, train_acc: 11.33%\n",
      "Epoch: 06\n",
      " | train_loss: 3.596123, train_acc: 12.12%\n",
      "  -> Save checkpoint for epoch 7\n",
      " | valid_loss: 3.741835, train_acc: 12.81%\n",
      "Epoch: 07\n",
      " | train_loss: 3.505066, train_acc: 14.07%\n",
      "  -> Save checkpoint for epoch 8\n",
      " | valid_loss: 3.740127, train_acc: 15.02%\n",
      "Epoch: 08\n",
      " | train_loss: 3.411820, train_acc: 16.43%\n",
      " | valid_loss: 3.334398, train_acc: 13.55%\n",
      "Epoch: 09\n",
      " | train_loss: 3.312577, train_acc: 17.72%\n",
      "  -> Save checkpoint for epoch 10\n",
      " | valid_loss: 3.400375, train_acc: 16.26%\n",
      "Epoch: 10\n",
      " | train_loss: 3.216365, train_acc: 19.59%\n",
      "  -> Save checkpoint for epoch 11\n",
      " | valid_loss: 3.330571, train_acc: 18.23%\n",
      "Epoch: 11\n",
      " | train_loss: 3.080617, train_acc: 21.99%\n",
      " | valid_loss: 3.501420, train_acc: 16.01%\n",
      "Epoch: 12\n",
      " | train_loss: 3.014467, train_acc: 23.89%\n",
      " | valid_loss: 3.543636, train_acc: 17.73%\n",
      "Epoch: 13\n",
      " | train_loss: 2.850721, train_acc: 27.03%\n",
      "  -> Save checkpoint for epoch 14\n",
      " | valid_loss: 3.289485, train_acc: 22.91%\n",
      "Epoch: 14\n",
      " | train_loss: 2.727633, train_acc: 28.98%\n",
      " | valid_loss: 3.467239, train_acc: 22.91%\n",
      "Epoch: 15\n",
      " | train_loss: 2.621025, train_acc: 31.13%\n",
      "  -> Save checkpoint for epoch 16\n",
      " | valid_loss: 3.018876, train_acc: 26.35%\n",
      "Epoch: 16\n",
      " | train_loss: 2.479552, train_acc: 33.94%\n",
      " | valid_loss: 3.262761, train_acc: 25.37%\n",
      "Epoch: 17\n",
      " | train_loss: 2.312125, train_acc: 38.04%\n",
      " | valid_loss: 2.909071, train_acc: 25.62%\n",
      "Epoch: 18\n",
      " | train_loss: 2.164669, train_acc: 40.12%\n",
      "  -> Save checkpoint for epoch 19\n",
      " | valid_loss: 2.633022, train_acc: 28.08%\n",
      "Epoch: 19\n",
      " | train_loss: 1.968478, train_acc: 45.46%\n",
      " | valid_loss: 3.378947, train_acc: 25.62%\n",
      "Epoch: 20\n",
      " | train_loss: 1.779667, train_acc: 49.30%\n",
      " | valid_loss: 3.006965, train_acc: 27.34%\n",
      "Epoch: 21\n",
      " | train_loss: 1.579670, train_acc: 56.47%\n",
      "  -> Save checkpoint for epoch 22\n",
      " | valid_loss: 3.307255, train_acc: 28.82%\n",
      "Epoch: 22\n",
      " | train_loss: 1.366031, train_acc: 60.79%\n",
      " | valid_loss: 3.475370, train_acc: 28.08%\n",
      "Epoch: 23\n",
      " | train_loss: 1.135627, train_acc: 65.88%\n",
      "  -> Save checkpoint for epoch 24\n",
      " | valid_loss: 3.551615, train_acc: 29.31%\n",
      "Epoch: 24\n",
      " | train_loss: 0.914650, train_acc: 72.21%\n",
      " | valid_loss: 3.519873, train_acc: 28.08%\n",
      "Epoch: 25\n",
      " | train_loss: 0.720843, train_acc: 78.46%\n",
      "  -> Save checkpoint for epoch 26\n",
      " | valid_loss: 3.791109, train_acc: 30.54%\n",
      "Epoch: 26\n",
      " | train_loss: 0.483027, train_acc: 85.50%\n",
      " | valid_loss: 4.305592, train_acc: 26.11%\n",
      "Epoch: 27\n",
      " | train_loss: 0.405677, train_acc: 88.74%\n",
      " | valid_loss: 3.920475, train_acc: 27.09%\n",
      "Epoch: 28\n",
      " | train_loss: 0.321348, train_acc: 91.24%\n",
      " | valid_loss: 4.557441, train_acc: 27.59%\n",
      "Epoch: 29\n",
      " | train_loss: 0.255142, train_acc: 92.84%\n",
      " | valid_loss: 4.304681, train_acc: 28.82%\n",
      "Epoch: 30\n",
      " | train_loss: 0.160936, train_acc: 95.72%\n",
      "  -> Save checkpoint for epoch 31\n",
      " | valid_loss: 4.514011, train_acc: 31.77%\n",
      "Epoch: 31\n",
      " | train_loss: 0.129467, train_acc: 96.86%\n",
      " | valid_loss: 4.448526, train_acc: 30.79%\n",
      "Epoch: 32\n",
      " | train_loss: 0.083385, train_acc: 98.25%\n",
      " | valid_loss: 4.905038, train_acc: 31.03%\n",
      "Epoch: 33\n",
      " | train_loss: 0.051045, train_acc: 99.04%\n",
      "  -> Save checkpoint for epoch 34\n",
      " | valid_loss: 4.801896, train_acc: 32.02%\n",
      "Epoch: 34\n",
      " | train_loss: 0.046585, train_acc: 98.99%\n",
      " | valid_loss: 4.731464, train_acc: 31.77%\n",
      "Epoch: 35\n",
      " | train_loss: 0.053915, train_acc: 98.84%\n",
      " | valid_loss: 4.683952, train_acc: 29.06%\n",
      "Epoch: 36\n",
      " | train_loss: 0.056372, train_acc: 98.66%\n",
      "  -> Save checkpoint for epoch 37\n",
      " | valid_loss: 4.924836, train_acc: 32.51%\n",
      "Epoch: 37\n",
      " | train_loss: 0.046831, train_acc: 98.99%\n",
      " | valid_loss: 5.119786, train_acc: 30.79%\n",
      "Epoch: 38\n",
      " | train_loss: 0.061030, train_acc: 98.43%\n",
      " | valid_loss: 5.339563, train_acc: 30.79%\n",
      "Epoch: 39\n",
      " | train_loss: 0.058097, train_acc: 98.43%\n",
      " | valid_loss: 4.412862, train_acc: 31.53%\n",
      "Epoch: 40\n",
      " | train_loss: 0.070905, train_acc: 98.23%\n",
      "  -> Save checkpoint for epoch 41\n",
      " | valid_loss: 4.858916, train_acc: 33.25%\n",
      "Epoch: 41\n",
      " | train_loss: 0.089834, train_acc: 97.39%\n",
      " | valid_loss: 5.488397, train_acc: 28.57%\n",
      "Epoch: 42\n",
      " | train_loss: 0.174473, train_acc: 94.96%\n",
      " | valid_loss: 5.448017, train_acc: 23.65%\n",
      "Epoch: 43\n",
      " | train_loss: 0.244224, train_acc: 92.61%\n",
      " | valid_loss: 5.936461, train_acc: 27.09%\n",
      "Epoch: 44\n",
      " | train_loss: 0.168476, train_acc: 95.06%\n",
      " | valid_loss: 4.969116, train_acc: 29.56%\n",
      "Epoch: 45\n",
      " | train_loss: 0.083087, train_acc: 97.52%\n",
      " | valid_loss: 5.169807, train_acc: 27.09%\n",
      "Epoch: 46\n",
      " | train_loss: 0.055797, train_acc: 98.56%\n",
      " | valid_loss: 4.633843, train_acc: 30.54%\n",
      "Epoch: 47\n",
      " | train_loss: 0.055887, train_acc: 98.53%\n",
      " | valid_loss: 5.467857, train_acc: 30.30%\n",
      "Epoch: 48\n",
      " | train_loss: 0.059676, train_acc: 98.35%\n",
      " | valid_loss: 4.939967, train_acc: 29.80%\n",
      "Epoch: 49\n",
      " | train_loss: 0.053778, train_acc: 98.53%\n",
      " | valid_loss: 5.652579, train_acc: 32.27%\n"
     ]
    }
   ],
   "source": [
    "model = settingA().to(device)\n",
    "train(model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de9865ccda6098b078ef1392bd6ff1290889aa8c91ce4253d5043d68b8c8de9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
