# data augmentation
dataset:
  common:
    NAME: ScanNet
    data_root: ./dataset_preprocessed
    voxel_size: 0.02
  train:
    split: train
    voxel_max: 64000  # using 32000 points can make training faster but achieves ~0.5 miou lower for PointNeXt-XL 
    loop: 6
  val:
    split: val
    voxel_max: null 
    presample: True
  test:
    split: val 
    voxel_max: null

no_label: False

feature_keys: pos,x,heights # appending heights has insiginificant effects on ScanNet

num_classes: 200
batch_size: 8
val_batch_size: 1

dataloader:
  num_workers: 6

datatransforms:
  train: [RandomRotateZ, RandomScale, ChromaticAutoContrast, RandomDropFeature, NumpyChromaticNormalize]
  val: [NumpyChromaticNormalize] 
  test: [PointsToTensor, NumpyChromaticNormalize] 
  vote: [ChromaticDropGPU]
  kwargs:
    color_drop: 0.2
    gravity_dim: 2
    rotate_dim: 2
    scale: [0.8, 1.2]
    mirror: [0.2, -1, -1]
    angle: 1 
    color_mean: [0.46259782, 0.46253258, 0.46253258]  # better than not add
    color_std: [0.693565  , 0.6852543 , 0.68061745]

# save_pred: True
# visualize: True
# ---------------------------------------------------------------------------- #
# Training cfgs
# ---------------------------------------------------------------------------- #
val_fn: validate
ignore_index: -100
epochs: 100

cls_weighed_loss: False

criterion_args:
  NAME: FocalLoss
  gamma: 1
  alpha: [3.65223838e-04, 1.86178605e-03, 4.64874343e-04, 3.62384362e-03,
  2.86270950e-03, 4.55276071e-03, 4.54144410e-03, 4.23406755e-03,
  5.60380991e-03, 1.14091627e-02, 4.45110518e-03, 2.99510295e-02,
  4.34243297e-02, 2.34202656e-02, 2.80689144e-03, 3.74573967e-02,
  4.53960516e-03, 2.01155664e-02, 5.90990613e-03, 1.27137379e-02,
  1.44974660e-02, 2.07597824e-02, 2.96250807e-02, 2.33639483e-02,
  5.02425082e-02, 9.29934579e-03, 5.58884784e-02, 2.60759423e-02,
  3.16311273e-02, 3.72259907e-02, 5.55018680e-02, 2.53944660e-02,
  5.56864345e-02, 3.57820460e-01, 1.73176009e-02, 3.80375010e-03,
  3.74403722e-02, 1.08715309e-01, 1.42452529e-01, 3.03707787e-01,
  1.15145861e-01, 4.37492054e-02, 3.71221076e-01, 9.71001294e-02,
  5.56042536e-02, 1.23999508e-02, 9.05019985e-02, 3.94607950e-02,
  1.34989001e-02, 3.53126399e-02, 3.58469410e-02, 1.05560453e-01,
  4.79218636e-02, 2.02621883e-01, 1.00084635e-01, 4.02837389e-01,
  7.11322894e-01, 9.18832728e-02, 9.48691719e-02, 6.52440530e-02,
  1.35450292e-01, 5.06173850e-02, 4.38915284e-02, 5.27634284e-01,
  4.38029565e-02, 5.41448369e-02, 1.60944304e-01, 3.09310494e-01,
  3.93340492e-02, 4.84620725e-01, 1.66697444e-01, 1.54875579e-01,
  4.59581931e-01, 7.80130900e-02, 2.74730510e-01, 2.66210666e+00,
  3.92431512e-02, 2.07900794e-01, 1.12340779e-01, 5.49495168e-01,
  2.44041670e-02, 6.53865494e-02, 5.32058225e-01, 4.47482324e-02,
  7.89112594e-01, 4.92612835e-01, 6.77459027e-01, 1.25331841e+00,
  3.65734092e-01, 2.63691255e-01, 2.53011606e-01, 3.25950880e-01,
  2.11376632e-01, 6.96200282e-01, 3.20973266e+00, 2.93934429e-01,
  1.72510606e+00, 1.63859392e-01, 4.57047880e-01, 2.57581529e-01,
  3.18903328e-02, 2.53263328e-02, 6.01233753e-01, 1.46401026e-01,
  3.48438519e-01, 3.23336471e-01, 2.39635294e-01, 1.39518361e+00,
  4.61822389e-01, 4.58517385e-01, 1.28208102e-01, 7.73285253e-01,
  4.08206075e+00, 1.41045138e-01, 1.71263112e+00, 2.06483090e-01,
  3.18430141e+00, 4.06949779e-02, 1.59904021e-02, 6.89432623e-01,
  1.05944126e-01, 1.47789340e+00, 6.53910629e-01, 2.78392430e+00,
  1.83261232e+00, 3.60975895e-01, 8.87606436e-01, 8.79250555e-01,
  3.00262970e-01, 1.73068892e-01, 4.04261754e-01, 2.14224122e+00,
  1.80149625e+00, 1.63252282e+00, 2.24318642e-01, 1.19534712e-01,
  4.08810042e-01, 2.66424575e+00, 1.08620928e+00, 6.13725838e+00,
  1.18099870e+00, 1.27770861e+01, 2.28752550e-01, 9.81979518e-01,
  1.62891370e+00, 8.40469922e-02, 9.38946221e-01, 3.16756995e+00,
  2.43932598e+00, 1.10780282e+00, 7.87098835e+00, 3.89047092e-01,
  2.22377857e+00, 7.37139582e-01, 3.65260682e-01, 2.61641653e+00,
  1.19483021e+01, 2.88882931e+00, 1.54611977e+00, 1.74439239e+00,
  1.44520163e+00, 2.86511458e+00, 2.33332431e+00, 5.12705530e-02,
  2.97368058e+00, 7.88690257e-01, 9.50725116e+00, 8.34599167e-01,
  2.04521649e-01, 3.79354577e-01, 2.54267933e+00, 2.50427027e-01,
  2.54904706e-02, 4.97347455e-02, 7.76068075e-02, 2.80198073e-01,
  1.24602969e-01, 4.62531051e-01, 3.01327200e-01, 1.35222424e+00,
  1.21676487e-01, 6.83816209e-01, 9.48359316e-02, 2.33455648e+00,
  9.46180735e-01, 3.74332920e+00, 2.53664895e-01, 1.26672544e+01,
  1.92714551e+00, 1.25974690e+00, 1.59809801e+00, 3.54909561e-01,
  4.30380821e-01, 1.01318681e+01, 9.58281457e+00, 2.98976902e+00,
  5.74188907e-01, 7.04334326e-01, 1.29758491e+00, 4.86041535e-01]


optimizer:
 NAME: 'adamw'  # better than adam
 weight_decay: 1.0e-4 # better than 0.5

# lr_scheduler:
lr: 0.001
min_lr: null

sched: multistep
decay_epochs: [70, 90]
decay_rate: 0.1
warmup_epochs: 0

grad_norm_clip: 10
use_voting: False
# ---------------------------------------------------------------------------- #
# io and misc
# ---------------------------------------------------------------------------- #
save_freq: -1 # save epoch every xxx epochs, -1 only save last and best. 
val_freq: 1

wandb:
  project: PointMetaBase-ScanNet